# ===========================================
# AI-Manager CMS - Configuration Environnement
# ===========================================

# Application
APP_NAME="AI-Manager CMS"
APP_ENV=local
APP_KEY=
APP_DEBUG=true
APP_TIMEZONE=Europe/Paris
APP_URL=http://localhost:8080

# Domaine pour Caddy
SITE_ADDRESS=localhost
ACME_EMAIL=admin@example.com

# ===========================================
# BASE DE DONNÉES
# ===========================================
DB_CONNECTION=pgsql
DB_HOST=db
DB_PORT=5432
DB_DATABASE=ai_manager
DB_USERNAME=postgres
DB_PASSWORD=secret
DB_EXTERNAL_PORT=5432

# ===========================================
# REDIS (OPTIONNEL)
# ===========================================
REDIS_ENABLED=false
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=null
REDIS_CLIENT=phpredis
CACHE_STORE=file
QUEUE_CONNECTION=database
SESSION_DRIVER=file

# ===========================================
# QDRANT - BASE VECTORIELLE
# ===========================================
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_API_KEY=
QDRANT_EXTERNAL_PORT=6333

# ===========================================
# OLLAMA - SERVEUR IA
# ===========================================
OLLAMA_HOST=ollama
OLLAMA_PORT=11434
OLLAMA_VERSION=0.13.5
OLLAMA_DEFAULT_MODEL=mistral:7b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_KEEP_ALIVE=5m
OLLAMA_NUM_PARALLEL=2
OLLAMA_EXTERNAL_PORT=11434

# Modèles IA à télécharger automatiquement au démarrage
# Séparés par des virgules
OLLAMA_MODELS=nomic-embed-text,mistral:7b

# Production : modèles plus puissants (décommenter)
# OLLAMA_MODELS=nomic-embed-text,llama3.3:70b,mistral-small

# ===========================================
# PORTS EXTERNES
# ===========================================
# Par défaut 8080 pour éviter les conflits avec Apache/Nginx existants
# Si port 80 disponible, vous pouvez l'utiliser
WEB_PORT=8080

# ===========================================
# REVERSE PROXY (CWP, Apache, Nginx)
# ===========================================
# Adresses IP des proxies de confiance
# * = tous les proxies (recommandé derrière CWP/Apache local)
# 127.0.0.1 = uniquement localhost
# Pour plusieurs IPs: 127.0.0.1,10.0.0.0/8
TRUSTED_PROXIES=*

# ===========================================
# MAIL
# ===========================================
MAIL_MAILER=log
MAIL_HOST=127.0.0.1
MAIL_PORT=2525
MAIL_USERNAME=null
MAIL_PASSWORD=null
MAIL_ENCRYPTION=null
MAIL_FROM_ADDRESS="noreply@ai-manager.local"
MAIL_FROM_NAME="${APP_NAME}"

# ===========================================
# WEBHOOKS
# ===========================================
WEBHOOK_SECRET=your-webhook-secret-change-in-production
WEBHOOK_TIMEOUT=30

# ===========================================
# LOGGING
# ===========================================
LOG_CHANNEL=stack
LOG_STACK=single
LOG_DEPRECATIONS_CHANNEL=null
LOG_LEVEL=debug

# ===========================================
# FILESYSTEM
# ===========================================
FILESYSTEM_DISK=local

# ===========================================
# BROADCAST
# ===========================================
BROADCAST_CONNECTION=log

# ===========================================
# VITE (DEV)
# ===========================================
VITE_APP_NAME="${APP_NAME}"
